# -*- coding: utf-8 -*-
"""LLM_LAB_1_FIN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ko2nq5wIqCQvwwljOV09oJ46NIXY9pxJ
"""

!pip install transformers torch sentence-transformers -q

from transformers import pipeline

# Load sentiment analysis model
sentiment_analyzer = pipeline("sentiment-analysis")

text = "I really love this product, it is amazing!"

result = sentiment_analyzer(text)

print(result)

from sentence_transformers import SentenceTransformer, util

# Load model
model = SentenceTransformer('all-MiniLM-L6-v2')

sentence1 = "I love artificial intelligence"
sentence2 = "I enjoy learning about AI"

# Convert sentences to embeddings
embedding1 = model.encode(sentence1, convert_to_tensor=True)
embedding2 = model.encode(sentence2, convert_to_tensor=True)

# Compute cosine similarity
similarity_score = util.cos_sim(embedding1, embedding2)

print("Similarity Score:", similarity_score.item())

from transformers import pipeline
news = "Donald Trump is still alive"
model1 = pipeline(
    "text-classification",
    model="mrm8488/bert-tiny-finetuned-fake-news-detection"
)

model2 = pipeline(
    "text-classification",
    model="distilbert-base-uncased-finetuned-sst-2-english"
)

label_map = {
    "LABEL_0": "FAKE",
    "LABEL_1": "REAL"
}

pred1 = label_map[model1(news)[0]["label"]]
pred2 = "REAL" if model2(news)[0]["label"] == "POSITIVE" else "FAKE"


votes = [pred1, pred2]
final_prediction = max(set(votes), key=votes.count)


print("News:", news)
print("Model 1 (Fake-News Model):", pred1)
print("Model 2 (Sentiment Model):", pred2)
print("Final Decision (Voting):", final_prediction)

